train_batch_size = 16
version_exp = 1
val_batch_size = 1
num_epochs = 16
learning_rate = 10**-4
sequence_length = 2000
dmodel = 512
inp_lang = "en"
out_lang = "fr"
model_folder = "files"
model_name = f"transformer_{version_exp}"
tokenizer_name = f"t_tokenizer_{version_exp}"
tokenizer_name_inp = f"t_tokenizer_{version_exp}_{inp_lang}"
tokenizer_name_out = f"t_tokenizer_{version_exp}_{out_lang}"
dff = 1
Nx = 1
train_size = 0.85
preload = False
h = 4
